"""
01. ìƒ˜í”Œ ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸
í•­ê³µí¸ ë° ê³ ê° ë°ì´í„°ë¥¼ ìƒì„±í•˜ì—¬ Raw ë ˆì´ì–´ì— ì €ì¥
"""

import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.spark_config import *
from pyspark.sql.types import *
import random
from datetime import datetime, timedelta


def generate_flight_data(num_flights=10000):
    """í•­ê³µí¸ ë°ì´í„° ìƒì„±"""
    print(f"Generating {num_flights:,} flight records...")

    airlines = ['AA', 'DL', 'UA', 'WN', 'B6', 'AS', 'NK', 'F9']
    airports = [
        'ATL', 'DFW', 'DEN', 'ORD', 'LAX', 'CLT', 'LAS', 'PHX',
        'MCO', 'SEA', 'EWR', 'SFO', 'DTW', 'BOS', 'MSP', 'FLL',
        'JFK', 'LGA', 'BWI', 'DCA', 'IAH', 'SLC', 'MDW', 'SAN'
    ]

    start_date = datetime.now() - timedelta(days=90)
    date_range = [start_date + timedelta(days=x) for x in range(90)]

    flight_data = []
    for i in range(num_flights):
        flight_date = random.choice(date_range).strftime('%Y-%m-%d')
        airline = random.choice(airlines)
        origin = random.choice(airports)
        dest = random.choice([a for a in airports if a != origin])
        distance = random.randint(200, 3000)

        # 75%ëŠ” ì •ìƒ ìš´í•­, 25%ëŠ” ì§€ì—°
        if random.random() < 0.75:
            arr_delay = random.randint(-15, 15)
            dep_delay = random.randint(-10, 20)
        else:
            arr_delay = random.randint(15, 180)
            dep_delay = random.randint(15, 150)

        flight_data.append({
            'flight_date': flight_date,
            'airline': airline,
            'origin': origin,
            'dest': dest,
            'arr_delay': arr_delay,
            'dep_delay': dep_delay,
            'distance': distance,
            'ingestion_timestamp': datetime.now().isoformat()
        })

    return flight_data


def generate_customer_data(num_customers=5000):
    """ê³ ê° ë°ì´í„° ìƒì„± (PII í¬í•¨)"""
    print(f"Generating {num_customers:,} customer records...")

    first_names = [
        'James', 'Mary', 'John', 'Patricia', 'Robert', 'Jennifer',
        'Michael', 'Linda', 'William', 'Elizabeth', 'David', 'Barbara',
        'Richard', 'Susan', 'Joseph', 'Jessica', 'Thomas', 'Sarah',
        'Charles', 'Karen', 'Daniel', 'Nancy', 'Matthew', 'Lisa'
    ]

    last_names = [
        'Smith', 'Johnson', 'Williams', 'Brown', 'Jones', 'Garcia',
        'Miller', 'Davis', 'Rodriguez', 'Martinez', 'Hernandez', 'Lopez',
        'Gonzalez', 'Wilson', 'Anderson', 'Thomas', 'Taylor', 'Moore',
        'Jackson', 'Martin', 'Lee', 'Thompson', 'White', 'Harris'
    ]

    countries = [
        'USA', 'Canada', 'UK', 'Germany', 'France', 'Japan',
        'Australia', 'South Korea', 'China', 'Brazil', 'Mexico',
        'Spain', 'Italy', 'India', 'Netherlands'
    ]

    segments = ['Economy', 'Premium Economy', 'Business', 'First Class']

    customer_data = []
    for i in range(num_customers):
        customer_id = f"CUST{str(i + 1).zfill(6)}"
        first_name = random.choice(first_names)
        last_name = random.choice(last_names)
        full_name = f"{first_name} {last_name}"
        email = f"{first_name.lower()}.{last_name.lower()}{random.randint(1, 999)}@example.com"
        phone = f"+1-{random.randint(200, 999)}-{random.randint(100, 999)}-{random.randint(1000, 9999)}"
        passport_no = f"P{random.randint(10000000, 99999999)}"
        country = random.choice(countries)
        segment = random.choice(segments)

        customer_data.append({
            'customer_id': customer_id,
            'full_name': full_name,
            'email': email,
            'phone': phone,
            'passport_no': passport_no,
            'country': country,
            'segment': segment,
            'ingestion_timestamp': datetime.now().isoformat()
        })

    return customer_data


def main():
    print("=" * 60)
    print("STEP 1: Generate Sample Data (Bronze Layer)")
    print("=" * 60)
    print()

    # Spark ì„¸ì…˜ ìƒì„±
    spark = get_spark_session("01_GenerateSampleData")

    # ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
    create_databases(spark)

    # ========================================
    # í•­ê³µí¸ ë°ì´í„° ìƒì„± ë° ì €ì¥
    # ========================================
    flight_data = generate_flight_data(num_flights=10000)

    schema_flights = StructType([
        StructField('flight_date', StringType(), True),
        StructField('airline', StringType(), True),
        StructField('origin', StringType(), True),
        StructField('dest', StringType(), True),
        StructField('arr_delay', IntegerType(), True),
        StructField('dep_delay', IntegerType(), True),
        StructField('distance', IntegerType(), True),
        StructField('ingestion_timestamp', StringType(), True)
    ])

    df_flights = spark.createDataFrame(flight_data, schema=schema_flights)

    df_flights.write \
        .format("delta") \
        .mode("overwrite") \
        .option("overwriteSchema", "true") \
        .saveAsTable(TABLE_FLIGHTS_RAW)

    flight_count = df_flights.count()
    print(f"âœ“ Saved {flight_count:,} flights â†’ {TABLE_FLIGHTS_RAW}")
    print()

    # ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    print("Sample Flight Data:")
    df_flights.show(5, truncate=False)

    # ========================================
    # ê³ ê° ë°ì´í„° ìƒì„± ë° ì €ì¥
    # ========================================
    customer_data = generate_customer_data(num_customers=5000)

    schema_customers = StructType([
        StructField('customer_id', StringType(), True),
        StructField('full_name', StringType(), True),
        StructField('email', StringType(), True),
        StructField('phone', StringType(), True),
        StructField('passport_no', StringType(), True),
        StructField('country', StringType(), True),
        StructField('segment', StringType(), True),
        StructField('ingestion_timestamp', StringType(), True)
    ])

    df_customers = spark.createDataFrame(customer_data, schema=schema_customers)

    df_customers.write \
        .format("delta") \
        .mode("overwrite") \
        .option("overwriteSchema", "true") \
        .saveAsTable(TABLE_CUSTOMER_RAW)

    customer_count = df_customers.count()
    print(f"âœ“ Saved {customer_count:,} customers â†’ {TABLE_CUSTOMER_RAW}")
    print()

    # ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    print("Sample Customer Data:")
    df_customers.show(5, truncate=False)

    # ========================================
    # ë°ì´í„° í’ˆì§ˆ ì²´í¬
    # ========================================
    print("=" * 60)
    print("DATA QUALITY CHECKS")
    print("=" * 60)

    # í•­ê³µí¸ ë°ì´í„° ì²´í¬
    print(f"\nâœˆï¸  Flight Data:")
    print(f"   Total Records: {flight_count:,}")
    print(
        f"   Date Range: {df_flights.agg({'flight_date': 'min'}).collect()[0][0]} to {df_flights.agg({'flight_date': 'max'}).collect()[0][0]}")
    print(f"   Unique Airlines: {df_flights.select('airline').distinct().count()}")
    print(f"   Unique Airports: {df_flights.select('origin').distinct().count()}")

    # ê³ ê° ë°ì´í„° ì²´í¬
    print(f"\nğŸ‘¤ Customer Data:")
    print(f"   Total Records: {customer_count:,}")
    print(f"   Unique Customers: {df_customers.select('customer_id').distinct().count()}")
    print(f"   Countries: {df_customers.select('country').distinct().count()}")
    print(f"   Segments: {df_customers.select('segment').distinct().count()}")

    print("\n" + "=" * 60)
    print("âœ… BRONZE LAYER CREATION COMPLETE")
    print("=" * 60)
    print(f"\nğŸ“ Tables created:")
    print(f"   â€¢ {TABLE_FLIGHTS_RAW}")
    print(f"   â€¢ {TABLE_CUSTOMER_RAW}")
    print(f"\nğŸ“‚ Data location: ./spark-warehouse/")
    print(f"\nğŸš€ Next step: python scripts/02_create_silver_layer.py")
    print()

    # Spark ì„¸ì…˜ ì¢…ë£Œ
    stop_spark_session(spark)


if __name__ == "__main__":
    main()