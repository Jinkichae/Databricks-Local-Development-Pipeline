"""
02. Silver ë ˆì´ì–´ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
Bronze(Raw) ë°ì´í„°ë¥¼ ì •ì œí•˜ì—¬ Silver ë ˆì´ì–´ë¡œ ë³€í™˜
"""

import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.spark_config import *
from pyspark.sql import functions as F


def create_flights_silver(spark):
    """í•­ê³µí¸ Silver í…Œì´ë¸” ìƒì„±"""
    print("Creating flights_silver table...")

    spark.sql(f"""
        CREATE OR REPLACE TABLE {TABLE_FLIGHTS_SILVER}
        USING DELTA
        AS
        SELECT
          flight_date,
          airline AS airline_code,
          origin AS origin_airport,
          dest AS dest_airport,
          CAST(arr_delay AS INT) AS arr_delay,
          CAST(dep_delay AS INT) AS dep_delay,
          CAST(distance AS INT) AS distance_miles,
          ingestion_timestamp,
          CURRENT_TIMESTAMP() AS transformation_timestamp
        FROM {TABLE_FLIGHTS_RAW}
        WHERE flight_date IS NOT NULL
          AND airline IS NOT NULL
          AND origin IS NOT NULL
          AND dest IS NOT NULL
    """)

    # ë°ì´í„° í’ˆì§ˆ ê²€ì¦
    df = spark.table(TABLE_FLIGHTS_SILVER)
    count = df.count()

    print(f"âœ“ Created {TABLE_FLIGHTS_SILVER}")
    print(f"  Records: {count:,}")

    # í†µê³„ ì •ë³´
    print(f"\n  Quality Checks:")
    print(f"    â€¢ Null arr_delay: {df.filter(F.col('arr_delay').isNull()).count()}")
    print(f"    â€¢ Null dep_delay: {df.filter(F.col('dep_delay').isNull()).count()}")
    print(f"    â€¢ Invalid dates: {df.filter(F.col('flight_date').isNull()).count()}")

    return count


def create_customer_silver(spark):
    """ê³ ê° Silver í…Œì´ë¸” ìƒì„±"""
    print("\nCreating customer_silver table...")

    spark.sql(f"""
        CREATE OR REPLACE TABLE {TABLE_CUSTOMER_SILVER}
        USING DELTA
        AS
        SELECT
          customer_id,
          full_name,
          email,
          phone,
          passport_no,
          country,
          segment,
          ingestion_timestamp,
          CURRENT_TIMESTAMP() AS transformation_timestamp
        FROM {TABLE_CUSTOMER_RAW}
        WHERE customer_id IS NOT NULL
    """)

    # ë°ì´í„° í’ˆì§ˆ ê²€ì¦
    df = spark.table(TABLE_CUSTOMER_SILVER)
    count = df.count()

    print(f"âœ“ Created {TABLE_CUSTOMER_SILVER}")
    print(f"  Records: {count:,}")

    # í†µê³„ ì •ë³´
    print(f"\n  Quality Checks:")
    print(f"    â€¢ Null emails: {df.filter(F.col('email').isNull()).count()}")
    print(f"    â€¢ Null phones: {df.filter(F.col('phone').isNull()).count()}")
    print(f"    â€¢ Duplicate customer_ids: {df.groupBy('customer_id').count().filter('count > 1').count()}")

    return count


def optimize_tables(spark):
    """Delta Lake í…Œì´ë¸” ìµœì í™”"""
    print("\nOptimizing Delta tables...")

    tables = [TABLE_FLIGHTS_SILVER, TABLE_CUSTOMER_SILVER]

    for table in tables:
        # Z-Ordering (ì£¼ìš” í•„í„° ì»¬ëŸ¼ ê¸°ì¤€ ìµœì í™”)
        if "flights" in table:
            spark.sql(f"OPTIMIZE {table} ZORDER BY (flight_date, airline_code)")
        else:
            spark.sql(f"OPTIMIZE {table} ZORDER BY (country, segment)")

        print(f"  âœ“ Optimized: {table}")


def show_sample_data(spark):
    """ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"""
    print("\n" + "=" * 60)
    print("SAMPLE DATA PREVIEW")
    print("=" * 60)

    print("\nâœˆï¸  Flights Silver (Top 5):")
    spark.table(TABLE_FLIGHTS_SILVER).show(5, truncate=False)

    print("\nğŸ‘¤ Customers Silver (Top 5):")
    spark.table(TABLE_CUSTOMER_SILVER) \
        .select("customer_id", "full_name", "email", "country", "segment") \
        .show(5, truncate=False)


def generate_statistics(spark):
    """í†µê³„ ì •ë³´ ìƒì„±"""
    print("\n" + "=" * 60)
    print("SILVER LAYER STATISTICS")
    print("=" * 60)

    # í•­ê³µí¸ í†µê³„
    print("\nâœˆï¸  Flight Statistics:")
    spark.sql(f"""
        SELECT 
            'Total Flights' AS metric,
            COUNT(*) AS value
        FROM {TABLE_FLIGHTS_SILVER}

        UNION ALL

        SELECT 
            'Unique Airlines' AS metric,
            COUNT(DISTINCT airline_code) AS value
        FROM {TABLE_FLIGHTS_SILVER}

        UNION ALL

        SELECT 
            'Unique Routes' AS metric,
            COUNT(DISTINCT CONCAT(origin_airport, '-', dest_airport)) AS value
        FROM {TABLE_FLIGHTS_SILVER}

        UNION ALL

        SELECT 
            'Avg Arrival Delay (min)' AS metric,
            CAST(AVG(arr_delay) AS INT) AS value
        FROM {TABLE_FLIGHTS_SILVER}
    """).show(truncate=False)

    # ê³ ê° í†µê³„
    print("\nğŸ‘¤ Customer Statistics:")
    spark.sql(f"""
        SELECT 
            'Total Customers' AS metric,
            COUNT(*) AS value
        FROM {TABLE_CUSTOMER_SILVER}

        UNION ALL

        SELECT 
            'Unique Countries' AS metric,
            COUNT(DISTINCT country) AS value
        FROM {TABLE_CUSTOMER_SILVER}

        UNION ALL

        SELECT 
            'Business Class %' AS metric,
            CAST(SUM(CASE WHEN segment = 'Business' THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS INT) AS value
        FROM {TABLE_CUSTOMER_SILVER}
    """).show(truncate=False)

    # êµ­ê°€ë³„ ê³ ê° ë¶„í¬
    print("\nğŸŒ Top 10 Countries by Customer Count:")
    spark.sql(f"""
        SELECT 
            country,
            COUNT(*) AS customer_count,
            ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) AS percentage
        FROM {TABLE_CUSTOMER_SILVER}
        GROUP BY country
        ORDER BY customer_count DESC
        LIMIT 10
    """).show(truncate=False)


def main():
    print("=" * 60)
    print("STEP 2: Create Silver Layer (Curated Data)")
    print("=" * 60)
    print()

    # Spark ì„¸ì…˜ ìƒì„±
    spark = get_spark_session("02_CreateSilverLayer")

    # Silver í…Œì´ë¸” ìƒì„±
    flights_count = create_flights_silver(spark)
    customer_count = create_customer_silver(spark)

    # í…Œì´ë¸” ìµœì í™”
    optimize_tables(spark)

    # ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    show_sample_data(spark)

    # í†µê³„ ì •ë³´ ìƒì„±
    generate_statistics(spark)

    # ìš”ì•½
    print("\n" + "=" * 60)
    print("âœ… SILVER LAYER CREATION COMPLETE")
    print("=" * 60)
    print(f"\nğŸ“Š Summary:")
    print(f"   â€¢ Flights processed: {flights_count:,}")
    print(f"   â€¢ Customers processed: {customer_count:,}")
    print(f"\nğŸ“ Tables created:")
    print(f"   â€¢ {TABLE_FLIGHTS_SILVER}")
    print(f"   â€¢ {TABLE_CUSTOMER_SILVER}")
    print(f"\nğŸ¯ Data Quality:")
    print(f"   â€¢ Validated and cleaned")
    print(f"   â€¢ Optimized with Z-Ordering")
    print(f"   â€¢ Ready for analytics")
    print(f"\nğŸš€ Next step: python scripts/03_create_mart_layer.py")
    print()

    # Spark ì„¸ì…˜ ì¢…ë£Œ
    stop_spark_session(spark)


if __name__ == "__main__":
    main()